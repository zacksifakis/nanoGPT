
step 1500: train loss 1.1477, val loss 1.4674
iter 1500: loss 1.2321, time 22728.52ms, mfu -100.00%
iter 1510: loss 1.2169, time 45.84ms, mfu 8.13%
iter 1520: loss 1.2432, time 46.22ms, mfu 8.12%
iter 1530: loss 1.2366, time 46.39ms, mfu 8.11%
iter 1540: loss 1.2264, time 46.36ms, mfu 8.11%
iter 1550: loss 1.2111, time 46.81ms, mfu 8.09%
iter 1560: loss 1.2161, time 46.34ms, mfu 8.09%
iter 1570: loss 1.2097, time 46.24ms, mfu 8.08%
iter 1580: loss 1.2148, time 46.31ms, mfu 8.08%
iter 1590: loss 1.2271, time 46.89ms, mfu 8.07%
iter 1600: loss 1.2189, time 46.57ms, mfu 8.06%
iter 1610: loss 1.2018, time 46.60ms, mfu 8.05%
iter 1620: loss 1.1904, time 46.48ms, mfu 8.05%
iter 1630: loss 1.1953, time 46.40ms, mfu 8.05%
iter 1640: loss 1.2136, time 46.79ms, mfu 8.04%
iter 1650: loss 1.2035, time 46.93ms, mfu 8.03%
iter 1660: loss 1.2234, time 47.30ms, mfu 8.01%
iter 1670: loss 1.1913, time 46.76ms, mfu 8.01%
iter 1680: loss 1.2095, time 46.82ms, mfu 8.00%
iter 1690: loss 1.2041, time 46.96ms, mfu 8.00%
iter 1700: loss 1.2021, time 46.59ms, mfu 8.00%
iter 1710: loss 1.1993, time 46.45ms, mfu 8.00%
iter 1720: loss 1.2068, time 46.95ms, mfu 7.99%
iter 1730: loss 1.1735, time 47.28ms, mfu 7.98%
iter 1740: loss 1.1726, time 46.81ms, mfu 7.98%
step 1750: train loss 1.1037, val loss 1.4743
iter 1750: loss 1.1493, time 18796.00ms, mfu 7.18%
iter 1760: loss 1.1689, time 46.23ms, mfu 7.27%
iter 1770: loss 1.1764, time 46.46ms, mfu 7.35%
iter 1780: loss 1.1833, time 46.40ms, mfu 7.42%
iter 1790: loss 1.2139, time 46.39ms, mfu 7.48%
iter 1800: loss 1.1972, time 47.04ms, mfu 7.52%
iter 1810: loss 1.2100, time 46.84ms, mfu 7.56%
iter 1820: loss 1.1606, time 46.62ms, mfu 7.61%
iter 1830: loss 1.1742, time 46.72ms, mfu 7.64%
iter 1840: loss 1.1631, time 46.83ms, mfu 7.68%
iter 1850: loss 1.1427, time 47.21ms, mfu 7.70%
iter 1860: loss 1.1416, time 47.29ms, mfu 7.72%
iter 1870: loss 1.1754, time 46.74ms, mfu 7.74%
iter 1880: loss 1.1738, time 46.70ms, mfu 7.77%
iter 1890: loss 1.1478, time 46.61ms, mfu 7.79%
iter 1900: loss 1.1562, time 46.67ms, mfu 7.81%
iter 1910: loss 1.1139, time 46.87ms, mfu 7.82%
iter 1920: loss 1.1692, time 47.17ms, mfu 7.83%
iter 1930: loss 1.1853, time 47.26ms, mfu 7.84%
iter 1940: loss 1.1393, time 46.72ms, mfu 7.85%
iter 1950: loss 1.1562, time 46.84ms, mfu 7.86%
iter 1960: loss 1.1311, time 46.62ms, mfu 7.87%
iter 1970: loss 1.1490, time 46.87ms, mfu 7.88%
iter 1980: loss 1.1433, time 47.13ms, mfu 7.88%
iter 1990: loss 1.1252, time 47.39ms, mfu 7.88%
step 2000: train loss 1.0550, val loss 1.4723
iter 2000: loss 1.1662, time 19094.21ms, mfu 7.10%
iter 2010: loss 1.1326, time 47.02ms, mfu 7.18%
iter 2020: loss 1.1392, time 47.02ms, mfu 7.25%
iter 2030: loss 1.1277, time 47.45ms, mfu 7.31%
iter 2040: loss 1.1444, time 46.92ms, mfu 7.38%
iter 2050: loss 1.1285, time 46.74ms, mfu 7.44%
iter 2060: loss 1.1549, time 46.54ms, mfu 7.49%
iter 2070: loss 1.1105, time 47.05ms, mfu 7.54%
iter 2080: loss 1.1091, time 47.05ms, mfu 7.57%
iter 2090: loss 1.1447, time 47.43ms, mfu 7.60%
iter 2100: loss 1.1360, time 46.50ms, mfu 7.64%
iter 2110: loss 1.1191, time 46.75ms, mfu 7.68%
iter 2120: loss 1.1077, time 46.81ms, mfu 7.70%
iter 2130: loss 1.1189, time 46.88ms, mfu 7.73%
iter 2140: loss 1.0791, time 46.95ms, mfu 7.75%
iter 2150: loss 1.1326, time 47.24ms, mfu 7.76%
iter 2160: loss 1.0893, time 46.81ms, mfu 7.78%
iter 2170: loss 1.1500, time 46.79ms, mfu 7.80%
iter 2180: loss 1.1121, time 46.96ms, mfu 7.81%
iter 2190: loss 1.1000, time 46.79ms, mfu 7.83%
iter 2200: loss 1.1071, time 47.08ms, mfu 7.84%
iter 2210: loss 1.0484, time 46.84ms, mfu 7.85%
iter 2220: loss 1.0728, time 47.56ms, mfu 7.85%
iter 2230: loss 1.1048, time 47.64ms, mfu 7.85%
iter 2240: loss 1.1006, time 47.33ms, mfu 7.85%
step 2250: train loss 1.0032, val loss 1.4825
iter 2250: loss 1.0889, time 18820.96ms, mfu 7.07%
iter 2260: loss 1.1111, time 48.18ms, mfu 7.13%
iter 2270: loss 1.0757, time 46.79ms, mfu 7.22%
iter 2280: loss 1.0793, time 46.82ms, mfu 7.29%
iter 2290: loss 1.0877, time 46.72ms, mfu 7.36%
iter 2300: loss 1.0834, time 46.64ms, mfu 7.42%
iter 2310: loss 1.0804, time 46.83ms, mfu 7.48%
iter 2320: loss 1.0764, time 47.28ms, mfu 7.52%
iter 2330: loss 1.0712, time 46.98ms, mfu 7.56%
iter 2340: loss 1.0827, time 46.74ms, mfu 7.60%
iter 2350: loss 1.0617, time 46.79ms, mfu 7.64%
iter 2360: loss 1.0754, time 46.93ms, mfu 7.67%
iter 2370: loss 1.0875, time 46.80ms, mfu 7.70%
iter 2380: loss 1.0899, time 47.21ms, mfu 7.72%
iter 2390: loss 1.0462, time 47.20ms, mfu 7.73%
iter 2400: loss 1.0568, time 46.76ms, mfu 7.76%
iter 2410: loss 1.0922, time 47.31ms, mfu 7.77%
iter 2420: loss 1.0751, time 46.71ms, mfu 7.79%
iter 2430: loss 1.0796, time 47.43ms, mfu 7.80%
iter 2440: loss 1.0939, time 47.16ms, mfu 7.81%
iter 2450: loss 1.0650, time 47.02ms, mfu 7.82%
iter 2460: loss 1.0754, time 47.64ms, mfu 7.82%
iter 2470: loss 1.0278, time 47.07ms, mfu 7.83%
iter 2480: loss 1.0609, time 47.30ms, mfu 7.83%
iter 2490: loss 1.0963, time 47.90ms, mfu 7.83%
[2023-10-13 01:06:40,978] torch._dynamo.convert_frame: [WARNING] torch._dynamo hit config.cache_size_limit (8)
[2023-10-13 01:06:40,978] torch._dynamo.convert_frame: [WARNING]    function: 'forward' (/home/workspace/model.py:170)
[2023-10-13 01:06:40,978] torch._dynamo.convert_frame: [WARNING] to diagnose recompilation issues, set env variable TORCHDYNAMO_REPORT_GUARD_FAILURES=1 and also see https://pytorch.org/docs/master/compile/troubleshooting.html.
step 2500: train loss 0.9584, val loss 1.5000
iter 2500: loss 1.0775, time 18640.22ms, mfu 7.05%
iter 2510: loss 1.0395, time 50.23ms, mfu 7.08%
iter 2520: loss 1.0680, time 47.96ms, mfu 7.15%
iter 2530: loss 1.0278, time 48.40ms, mfu 7.21%
iter 2540: loss 1.0509, time 48.07ms, mfu 7.26%
iter 2550: loss 1.0753, time 48.40ms, mfu 7.31%
iter 2560: loss 1.0458, time 48.21ms, mfu 7.35%
iter 2570: loss 1.0513, time 50.58ms, mfu 7.35%
iter 2580: loss 1.0436, time 50.49ms, mfu 7.35%
iter 2590: loss 1.0405, time 48.05ms, mfu 7.39%
iter 2600: loss 1.0099, time 47.84ms, mfu 7.43%
iter 2610: loss 1.0434, time 48.74ms, mfu 7.45%
iter 2620: loss 1.0198, time 48.47ms, mfu 7.48%
iter 2630: loss 1.0513, time 50.56ms, mfu 7.47%
iter 2640: loss 1.0673, time 48.24ms, mfu 7.49%
iter 2650: loss 1.0166, time 48.46ms, mfu 7.51%
iter 2660: loss 1.0378, time 48.98ms, mfu 7.52%
iter 2670: loss 1.0400, time 49.79ms, mfu 7.52%
iter 2680: loss 1.0084, time 48.49ms, mfu 7.53%
iter 2690: loss 1.0064, time 50.68ms, mfu 7.52%
iter 2700: loss 1.0546, time 48.21ms, mfu 7.54%
iter 2710: loss 1.0218, time 48.64ms, mfu 7.55%
iter 2720: loss 1.0098, time 50.43ms, mfu 7.53%
iter 2730: loss 1.0096, time 50.71ms, mfu 7.52%
iter 2740: loss 1.0096, time 48.40ms, mfu 7.53%
step 2750: train loss 0.9092, val loss 1.5216
iter 2750: loss 1.0216, time 18444.31ms, mfu 6.78%
iter 2760: loss 1.0109, time 48.04ms, mfu 6.88%
iter 2770: loss 0.9922, time 48.04ms, mfu 6.97%
iter 2780: loss 1.0202, time 47.97ms, mfu 7.05%
iter 2790: loss 1.0046, time 48.23ms, mfu 7.12%
iter 2800: loss 1.0015, time 50.55ms, mfu 7.14%
iter 2810: loss 0.9883, time 48.34ms, mfu 7.20%
iter 2820: loss 0.9924, time 51.12ms, mfu 7.21%
iter 2830: loss 1.0056, time 48.01ms, mfu 7.26%
iter 2840: loss 0.9884, time 48.89ms, mfu 7.30%
iter 2850: loss 0.9904, time 48.96ms, mfu 7.33%
iter 2860: loss 1.0042, time 48.84ms, mfu 7.36%
iter 2870: loss 0.9591, time 50.61ms, mfu 7.36%
iter 2880: loss 0.9891, time 49.17ms, mfu 7.38%
iter 2890: loss 0.9844, time 48.99ms, mfu 7.40%
iter 2900: loss 1.0000, time 48.13ms, mfu 7.44%
iter 2910: loss 0.9800, time 48.02ms, mfu 7.47%
iter 2920: loss 0.9818, time 48.94ms, mfu 7.48%
iter 2930: loss 0.9819, time 50.78ms, mfu 7.47%
iter 2940: loss 0.9738, time 50.49ms, mfu 7.46%
iter 2950: loss 0.9446, time 48.48ms, mfu 7.48%
iter 2960: loss 0.9820, time 47.98ms, mfu 7.51%
iter 2970: loss 1.0021, time 48.34ms, mfu 7.53%
iter 2980: loss 0.9684, time 47.71ms, mfu 7.56%
iter 2990: loss 0.9664, time 50.20ms, mfu 7.55%
step 3000: train loss 0.8622, val loss 1.5577
iter 3000: loss 0.9800, time 18099.38ms, mfu 6.79%
iter 3010: loss 0.9982, time 47.89ms, mfu 6.89%
iter 3020: loss 1.0151, time 48.16ms, mfu 6.98%
iter 3030: loss 0.9678, time 48.66ms, mfu 7.04%
iter 3040: loss 0.9922, time 47.96ms, mfu 7.12%
iter 3050: loss 0.9766, time 48.23ms, mfu 7.18%
iter 3060: loss 0.9993, time 48.73ms, mfu 7.22%
iter 3070: loss 1.0175, time 50.89ms, mfu 7.23%
iter 3080: loss 0.9850, time 48.28ms, mfu 7.28%
iter 3090: loss 0.9699, time 48.66ms, mfu 7.32%
iter 3100: loss 0.9731, time 48.08ms, mfu 7.36%
iter 3110: loss 0.9927, time 48.00ms, mfu 7.40%
iter 3120: loss 0.9689, time 48.06ms, mfu 7.44%
iter 3130: loss 0.9797, time 50.55ms, mfu 7.43%
iter 3140: loss 0.9556, time 50.66ms, mfu 7.42%
iter 3150: loss 0.9875, time 50.77ms, mfu 7.42%
iter 3160: loss 0.9910, time 48.86ms, mfu 7.44%
iter 3170: loss 0.9804, time 50.82ms, mfu 7.43%
iter 3180: loss 0.9901, time 48.72ms, mfu 7.45%
iter 3190: loss 0.9761, time 50.39ms, mfu 7.44%
iter 3200: loss 0.9822, time 49.07ms, mfu 7.46%
iter 3210: loss 0.9591, time 50.78ms, mfu 7.45%
iter 3220: loss 0.9791, time 48.19ms, mfu 7.47%
iter 3230: loss 0.9811, time 50.45ms, mfu 7.47%
iter 3240: loss 0.9712, time 48.61ms, mfu 7.49%
step 3250: train loss 0.8181, val loss 1.5611
iter 3250: loss 0.9600, time 18318.86ms, mfu 6.74%
iter 3260: loss 0.9416, time 48.10ms, mfu 6.84%
iter 3270: loss 0.9469, time 50.29ms, mfu 6.90%
iter 3280: loss 0.9507, time 48.48ms, mfu 6.98%
iter 3290: loss 0.9519, time 48.41ms, mfu 7.05%
iter 3300: loss 0.9533, time 48.29ms, mfu 7.11%
iter 3310: loss 0.9455, time 48.99ms, mfu 7.16%
iter 3320: loss 0.9371, time 48.06ms, mfu 7.22%
iter 3330: loss 0.9712, time 48.41ms, mfu 7.27%
iter 3340: loss 0.9732, time 48.76ms, mfu 7.31%
iter 3350: loss 0.9355, time 49.03ms, mfu 7.34%
iter 3360: loss 0.9674, time 48.78ms, mfu 7.37%
iter 3370: loss 0.9507, time 48.64ms, mfu 7.40%
iter 3380: loss 0.9593, time 48.04ms, mfu 7.43%
iter 3390: loss 0.9470, time 47.93ms, mfu 7.47%
iter 3400: loss 0.9441, time 48.73ms, mfu 7.48%
iter 3410: loss 0.9476, time 48.40ms, mfu 7.51%
iter 3420: loss 0.9359, time 48.71ms, mfu 7.52%
iter 3430: loss 0.9432, time 50.39ms, mfu 7.51%
iter 3440: loss 0.9456, time 48.12ms, mfu 7.53%
iter 3450: loss 0.9327, time 50.43ms, mfu 7.52%
iter 3460: loss 0.9265, time 50.59ms, mfu 7.50%
iter 3470: loss 0.9512, time 48.97ms, mfu 7.51%
iter 3480: loss 0.9219, time 48.88ms, mfu 7.52%
iter 3490: loss 0.9109, time 48.97ms, mfu 7.53%
[2023-10-13 01:08:43,506] torch._dynamo.convert_frame: [WARNING] torch._dynamo hit config.cache_size_limit (8)
[2023-10-13 01:08:43,506] torch._dynamo.convert_frame: [WARNING]    function: 'forward' (/home/workspace/model.py:103)
[2023-10-13 01:08:43,506] torch._dynamo.convert_frame: [WARNING] to diagnose recompilation issues, set env variable TORCHDYNAMO_REPORT_GUARD_FAILURES=1 and also see https://pytorch.org/docs/master/compile/troubleshooting.html.
[2023-10-13 01:08:47,216] torch._dynamo.convert_frame: [WARNING] torch._dynamo hit config.cache_size_limit (8)
[2023-10-13 01:08:47,216] torch._dynamo.convert_frame: [WARNING]    function: 'forward' (/home/workspace/model.py:26)
[2023-10-13 01:08:47,216] torch._dynamo.convert_frame: [WARNING] to diagnose recompilation issues, set env variable TORCHDYNAMO_REPORT_GUARD_FAILURES=1 and also see https://pytorch.org/docs/master/compile/troubleshooting.html.
step 3500: train loss 0.7769, val loss 1.5783
iter 3500: loss 0.9352, time 16660.66ms, mfu 6.78%
iter 3510: loss 0.9543, time 55.07ms, mfu 6.78%
iter 3520: loss 0.9692, time 55.11ms, mfu 6.78%
iter 3530: loss 0.9380, time 52.80ms, mfu 6.81%
iter 3540: loss 0.9164, time 54.96ms, mfu 6.80%
iter 3550: loss 0.9476, time 52.86ms, mfu 6.83%
iter 3560: loss 0.9192, time 53.12ms, mfu 6.85%
iter 3570: loss 0.9510, time 52.79ms, mfu 6.87%
iter 3580: loss 0.9261, time 52.80ms, mfu 6.89%
iter 3590: loss 0.9121, time 52.90ms, mfu 6.90%
iter 3600: loss 0.9206, time 55.11ms, mfu 6.89%
iter 3610: loss 0.9096, time 55.32ms, mfu 6.87%
iter 3620: loss 0.9121, time 52.78ms, mfu 6.89%
iter 3630: loss 0.9062, time 55.27ms, mfu 6.88%
iter 3640: loss 0.9317, time 55.28ms, mfu 6.86%
iter 3650: loss 0.9336, time 53.41ms, mfu 6.87%
iter 3660: loss 0.8992, time 55.28ms, mfu 6.86%
iter 3670: loss 0.8957, time 52.85ms, mfu 6.88%
iter 3680: loss 0.9155, time 54.01ms, mfu 6.88%
iter 3690: loss 0.9064, time 52.82ms, mfu 6.90%
iter 3700: loss 0.9354, time 55.25ms, mfu 6.88%
iter 3710: loss 0.8996, time 53.63ms, mfu 6.89%
iter 3720: loss 0.9158, time 55.31ms, mfu 6.88%
iter 3730: loss 0.9134, time 55.34ms, mfu 6.86%
iter 3740: loss 0.9238, time 55.18ms, mfu 6.85%
step 3750: train loss 0.7387, val loss 1.6117
iter 3750: loss 0.8906, time 15139.70ms, mfu 6.17%
iter 3760: loss 0.9024, time 52.90ms, mfu 6.26%
iter 3770: loss 0.9127, time 55.20ms, mfu 6.30%
iter 3780: loss 0.8797, time 55.23ms, mfu 6.35%
iter 3790: loss 0.8851, time 55.20ms, mfu 6.39%
Traceback (most recent call last):
  File "train.py", line 303, in <module>
    X, Y = get_batch('train')
  File "train.py", line 121, in get_batch
    x = torch.stack([torch.from_numpy((data[i:i+block_size]).astype(np.int64)) for i in ix])
  File "train.py", line 121, in <listcomp>
    x = torch.stack([torch.from_numpy((data[i:i+block_size]).astype(np.int64)) for i in ix])
KeyboardInterrupt